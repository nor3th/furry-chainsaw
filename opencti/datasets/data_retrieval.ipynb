{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download geckodriver from https://github.com/mozilla/geckodriver/releases/tag/v0.29.1\n",
    "# Download debian countries\n",
    "# download ISO countries\n",
    "# import other mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import selenium\n",
    "import time\n",
    "import bs4\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Download geckodriver from https://github.com/mozilla/geckodriver/releases/tag/v0.29.1 and unpack it\n",
    "GECKODRIVER_PATH = \"./geckodriver\"\n",
    "ISO_URL = \"https://www.iso.org/obp/ui/#search/code/\"\n",
    "DEBIAN_URL = \"https://salsa.debian.org/iso-codes-team/iso-codes/-/raw/main/data/iso_3166-1.json\"\n",
    "\n",
    "STIX_PATH = \"../data/geography.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download country list form iso.org\n",
    "\n",
    "def download_iso_table(url: str) -> dict:\n",
    "    driver = webdriver.Firefox(executable_path=GECKODRIVER_PATH)\n",
    "    driver.implicitly_wait(10) # seconds\n",
    "    driver.get(url)\n",
    "    ddelement = Select(driver.find_element_by_xpath(\"//select[@class='v-select-select']\"))\n",
    "    ddelement.select_by_value('8')\n",
    "    # TODO replace sleep with selenium wait for element\n",
    "    time.sleep(4)\n",
    "    bs4_code = bs4.BeautifulSoup(driver.page_source, 'lxml')\n",
    "    driver.quit()\n",
    "    \n",
    "    return bs4_code\n",
    "\n",
    "\n",
    "# Credits to https://stackoverflow.com/a/58274853\n",
    "def tableDataText(table) -> list: \n",
    "    \"\"\"Parses a html segment started with tag <table> followed \n",
    "    by multiple <tr> (table rows) and inner <td> (table data) tags. \n",
    "    It returns a list of rows with inner columns. \n",
    "    Accepts only one <th> (table header/data) in the first row.\n",
    "    \"\"\"\n",
    "    def rowgetDataText(tr, coltag='td'): # td (data) or th (header)       \n",
    "        return [td.get_text(strip=True) for td in tr.find_all(coltag)]  \n",
    "    rows = []\n",
    "    trs = table.find_all('tr')\n",
    "    headerow = rowgetDataText(trs[0], 'th')\n",
    "    if headerow: # if there is a header row include first\n",
    "        rows.append(headerow)\n",
    "        trs = trs[1:]\n",
    "    for tr in trs: # for every table row\n",
    "        rows.append(rowgetDataText(tr, 'td') ) # data row       \n",
    "    return rows\n",
    "\n",
    "def convert_table_to_dict(table_content: list[list[str]]) -> dict:\n",
    "    # first row is header\n",
    "    country_dict = {}\n",
    "    for entry in table_content[1:]:\n",
    "        country_dict[entry[3]] = {\n",
    "            # replace because of instances like \"Western Sahara*\" on iso.org\n",
    "            'names': set([entry[0].replace('*', '')]),\n",
    "            'alpha_2': entry[2],\n",
    "            'alpha_3': entry[3]\n",
    "        }\n",
    "    \n",
    "    return country_dict\n",
    "\n",
    "def get_iso_countries() -> dict:\n",
    "    bs4_code = download_iso_table(ISO_URL)\n",
    "    \n",
    "    table = bs4_code.find(\"div\", {\"class\": \"v-grid-tablewrapper\"}).find('table')\n",
    "    table_content = tableDataText(table)\n",
    "    \n",
    "    country_dict = convert_table_to_dict(table_content)\n",
    "    return country_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str) -> dict:\n",
    "     return json.loads(requests.get(url).content)\n",
    "    \n",
    "def convert_dict_to_dict(json_content: dict) -> dict:\n",
    "    country_list = json_content['3166-1']\n",
    "    country_dict = {}\n",
    "    for entry in country_list:\n",
    "        country_dict[entry['alpha_3']] = {\n",
    "            'names': set([entry['name'], entry.get('official_name', entry['name'])]),\n",
    "            'alpha_2': entry['alpha_2'],\n",
    "            'alpha_3': entry['alpha_3']\n",
    "        }\n",
    "        \n",
    "    return country_dict\n",
    "\n",
    "def get_debian_countries() -> dict:\n",
    "    content = download(DEBIAN_URL)\n",
    "    country_table = convert_dict_to_dict(content)\n",
    "    return country_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other relevant names which are not present in either of the other datasets\n",
    "\n",
    "custom_country_dict = {\n",
    "    'BES': {'names': set(['Bonaire'])},\n",
    "    'CIV': {'names': set(['Ivory Coast'])},\n",
    "    'FLK': {'names': set(['Falkland Islands'])},\n",
    "    'FSM': {'names': set(['Micronesia'])},\n",
    "    'IRN': {'names': set(['Iran'])},\n",
    "    'KOR': {'names': set(['South Korea'])},\n",
    "    'LAO': {'names': set(['Laos'])},\n",
    "    'MDA': {'names': set(['Moldova'])},\n",
    "    'PRK': {'names': set(['North Kora'])},\n",
    "    'PSE': {'names': set(['Palestine'])},\n",
    "    'RUS': {'names': set(['Russia'])},\n",
    "    'SXM': {'names': set(['Sint Maarten'])},\n",
    "    'MAF': {'names': set(['Saint Martin'])},\n",
    "    'TWN': {'names': set(['Taiwan'])},\n",
    "    'TZA': {'names': set(['Tanzania'])},\n",
    "    'SYR': {'names': set(['Syria'])},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(countries: list[dict]) -> dict:\n",
    "    main_dict = countries[0].copy()\n",
    "    for dictionary in countries[1:]:\n",
    "        for key in dictionary.keys():\n",
    "            main_dict[key]['names'].update(dictionary[key]['names'])\n",
    "    \n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "debian_country_dict = get_debian_countries()\n",
    "iso_country_dict = get_iso_countries()\n",
    "\n",
    "merged_dicts = merge_dicts([debian_country_dict, iso_country_dict, custom_country_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stix_with_dicts(stix_content: dict, merged_dict: dict) -> dict:\n",
    "    objects = stix_content['objects']\n",
    "    processed_countries = set()\n",
    "    \n",
    "    for entry_object in objects:\n",
    "        if 'country' in entry_object:        \n",
    "            country_specs = merged_dict.get(entry_object['country'], None)\n",
    "            if country_specs is None:\n",
    "                print(f\"A strange country is found. Investigate!! '{entry_object['country']}'\")\n",
    "                continue\n",
    "                \n",
    "            names = country_specs['names'] - set([entry_object['name']]) - set(entry_object['x_opencti_aliases'])\n",
    "            entry_object['x_opencti_aliases'] += names\n",
    "            processed_countries.add(entry_object['country'])\n",
    "    \n",
    "    diff = merged_dict.keys() - processed_countries\n",
    "    if diff:\n",
    "        print(f\"Unprocessed countries {diff}\")\n",
    "    \n",
    "    return stix_content\n",
    "\n",
    "def modify_stix(stix_file: str, merged_dict: dict) -> None:\n",
    "    with open(stix_file, 'r') as f:\n",
    "        stix_data = json.load(f)\n",
    "        content = merge_stix_with_dicts(stix_data, merged_dict)\n",
    "        \n",
    "    base_name, ext = os.path.splitext(stix_file)\n",
    "    new_file_name = f\"{base_name}_new{ext}\"\n",
    "    with open(new_file_name, \"w\") as f:\n",
    "        json.dump(content,f, indent=4)\n",
    "        \n",
    "    print(\"All done here!\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stix_content = modify_stix(STIX_PATH, merged_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
